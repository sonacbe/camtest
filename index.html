<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>실시간 얼굴 인식 웹페이지</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-detection"></script>
    <style>
        body { margin: 0; display: flex; flex-direction: column; align-items: center; justify-content: center; background: #000; height: 100vh; overflow: hidden; }
        .container { position: relative; width: 100%; max-width: 500px; }
        video, canvas { position: absolute; top: 0; left: 0; width: 100%; height: auto; border-radius: 10px; }
        #status { position: fixed; top: 10px; color: white; background: rgba(0,0,0,0.5); padding: 5px 10px; z-index: 10; font-family: sans-serif; }
    </style>
</head>
<body>

    <div id="status">모델 로딩 중...</div>
    <div class="container">
        <video id="video" autoplay playsinline muted></video>
        <canvas id="canvas"></canvas>
    </div>

    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const status = document.getElementById('status');

        let detector;

        // 1. 카메라 설정
        async function setupCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: "user", width: 640, height: 480 }, // 전면 카메라
                audio: false
            });
            video.srcObject = stream;
            return new Promise((resolve) => {
                video.onloadedmetadata = () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    resolve(video);
                };
            });
        }

        // 2. 모델 로드 및 인식 루프
        async function loadModel() {
            const model = faceDetection.SupportedModels.MediaPipeFaceDetector;
            const detectorConfig = { runtime: 'tfjs', modelType: 'short' };
            detector = await faceDetection.createDetector(model, detectorConfig);
            status.innerText = "인식 준비 완료!";
            detectFace();
        }

        // 3. 얼굴 감지 및 그리기
        async function detectFace() {
            const faces = await detector.estimateFaces(video);
            
            ctx.clearRect(0, 0, canvas.width, canvas.height); // 캔버스 초기화

            faces.forEach(face => {
                const { xMin, yMin, width, height } = face.box;

                // 바운딩 박스 그리기
                ctx.strokeStyle = "#00FF00"; // 형광 초록색
                ctx.lineWidth = 4;
                ctx.strokeRect(xMin, yMin, width, height);

                // 상단에 인식 정보 표시 (선택 사항)
                ctx.fillStyle = "#00FF00";
                ctx.font = "18px sans-serif";
                ctx.fillText(`Face: ${Math.round(face.score[0] * 100)}%`, xMin, yMin - 10);
            });

            requestAnimationFrame(detectFace); // 무한 반복
        }

        // 실행
        setupCamera().then(loadModel);
    </script>
</body>
</html>